{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bffce6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import peakutils as pu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "import heapq\n",
    "import json\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from datetime import datetime, timedelta, date\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm, trange\n",
    "from scipy.fft import ifft\n",
    "from scipy import signal\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from tensorflow.keras.utils import to_categorical  \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4bd6fc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "window_size_features = 5\n",
    "runs = 1\n",
    "k = 1000\n",
    "U_prime_size = 5000\n",
    "\n",
    "DATA = 0\n",
    "\n",
    "REBUILD = False\n",
    "\n",
    "# IM - Individual Model\n",
    "# GM - Group Model\n",
    "MODEL_TYPE = 'IM'\n",
    "\n",
    "# OS - Over Sample\n",
    "# US - Under Sample\n",
    "# NA - None\n",
    "SAMPLE_TYPE = 'NA'\n",
    "\n",
    "# 0 - Neural Network\n",
    "# 1 - KNN\n",
    "# 2 - Random Forest\n",
    "# 3 - GaussianNB\n",
    "# 4 - AdaBoostClassifier\n",
    "\n",
    "model_to_use = 2\n",
    "\n",
    "# testing_range = [x/10 for x in range(2,10)] + [x for x in range(1,5)] + [x for x in range(5, 100, 5)] + [x for x in range(96,100)]\n",
    "testing_range = [x/10 for x in range(4,10)] + [x for x in range(1,5)] + [x for x in range(95,99)]\n",
    "# testing_range = [x for x in range(95,99)]\n",
    "subjects = [ \"S\" + str(i) for i in range(2, 18) if i != 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231a852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54356ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - Neural Network\n",
    "# 1 - KNN\n",
    "# 2 - Random Forrest\n",
    "# 3 - GaussianNB\n",
    "# 4 - AdaBoostClassifier\n",
    "\n",
    "models_dict = {\n",
    "    '0': 'Deep Neural Network',\n",
    "    '1': 'k-Nearest Neighbors', \n",
    "    '2': 'Random Forest',\n",
    "    '3': 'Gaussian Naive Bayes',\n",
    "    '4': 'AdaBoost'\n",
    "}\n",
    "\n",
    "model_to_use = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3284a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_multiple_estimator(estimators, X_list, model_to_use, weights = None):\n",
    "\n",
    "    if model_to_use == 0:\n",
    "        pred1 = np.asarray([clf.predict(X) for clf, X in zip(estimators, X_list)])\n",
    "    else:\n",
    "        pred1 = np.asarray([clf.predict_proba(X) for clf, X in zip(estimators, X_list)])\n",
    "    pred2 = np.average(pred1, axis=0, weights=weights)\n",
    "    pred = np.argmax(pred2, axis=1)\n",
    "\n",
    "    # Convert integer predictions to original labels:\n",
    "    return np.round(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_with_gm_or_im_data(test_subject, MODEL_TYPE):\n",
    "    \n",
    "    if MODEL_TYPE == 'GM':\n",
    "        data = pd.concat([all_features[subject] for subject in all_features.keys() if subject != test_subject])\n",
    "        X_train = data.loc[:, data.columns != 'Label']\n",
    "        y_train = data['Label']\n",
    "        X_test = all_features[test_subject].loc[:, data.columns != 'Label']\n",
    "        y_test = all_features[test_subject]['Label']\n",
    "    elif MODEL_TYPE == 'IM':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(all_features[test_subject].loc[:, all_features[test_subject].columns != 'Label'], all_features[test_subject]['Label'], test_size=0.20)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae96667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filer_and_clean_data(X_train, X_test):\n",
    "\n",
    "    filter_col = [col for col in X_train if 'BVP' in col or 'ECG' in col or 'SCR' in col or 'SCL' in col or 'ACC' in col]\n",
    "    X_train = X_train[filter_col]\n",
    "    \n",
    "    view_1_ind = [list(X_train.keys()).index(i) for i in X_train.keys() if 'BVP' in i or 'ECG' in i]\n",
    "    view_2_ind = [list(X_train.keys()).index(i) for i in X_train.keys() if 'SCR' in i or 'SCL' in i or 'ACC' in i]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = X_test[filter_col]\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, view_1_ind, view_2_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406377c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(all_models=True):\n",
    "    \n",
    "    if all_models:\n",
    "        if model_to_use == 0: model_1, model_2, model_3, model_4 = baseline_model(21), baseline_model(25), baseline_model(46), baseline_model(46)\n",
    "        elif model_to_use == 1: model_1, model_2, model_3, model_4 = KNeighborsClassifier(n_neighbors=4), KNeighborsClassifier(n_neighbors=4), KNeighborsClassifier(n_neighbors=4), KNeighborsClassifier(n_neighbors=4)\n",
    "        elif model_to_use == 2: model_1, model_2, model_3, model_4 = RandomForestClassifier(n_estimators=100), RandomForestClassifier(n_estimators=100), RandomForestClassifier(n_estimators=100), RandomForestClassifier(n_estimators=100)\n",
    "        elif model_to_use == 3: model_1, model_2, model_3, model_4 = GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB()\n",
    "        elif model_to_use == 4: model_1, model_2, model_3, model_4 = AdaBoostClassifier(), AdaBoostClassifier(), AdaBoostClassifier(), AdaBoostClassifier() \n",
    "\n",
    "        return model_1, model_2, model_3, model_4\n",
    "    else:\n",
    "        if model_to_use == 0: model = baseline_model(46)\n",
    "        elif model_to_use == 1: model = KNeighborsClassifier(n_neighbors=4)\n",
    "        elif model_to_use == 2: model = RandomForestClassifier(n_estimators=100)\n",
    "        elif model_to_use == 3: model = GaussianNB()\n",
    "        elif model_to_use == 4: model = AdaBoostClassifier()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ecec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_labels(model_1, model_2, Unlabeled_X_train_half_1, Unlabeled_X_train_half_2, Labeled_X_train, Labeled_y_train, Unlabeled_X_train):\n",
    "    vals_to_del = []\n",
    "    \n",
    "    if model_to_use == 0:\n",
    "        predict_1 = model_1.predict(Unlabeled_X_train_half_1)\n",
    "        predict_2 = model_2.predict(Unlabeled_X_train_half_2)\n",
    "    else:\n",
    "        predict_1 = model_1.predict_proba(Unlabeled_X_train_half_1)\n",
    "        predict_2 = model_2.predict_proba(Unlabeled_X_train_half_2)\n",
    "        \n",
    "        if len(predict_1[0]) == 1:\n",
    "            predict_1 = model_1.predict(Unlabeled_X_train_half_1)\n",
    "        if len(predict_2[0]) == 1:\n",
    "            predict_2 = model_2.predict(Unlabeled_X_train_half_2)\n",
    "        \n",
    "    if predict_1.ndim == 2:\n",
    "        best_values_1 = list(set(np.concatenate((predict_1[:,0].argsort()[-k:][::-1], predict_1[:,1].argsort()[-k:][::-1]))))\n",
    "    else:\n",
    "        best_values_1 = list(set(list(predict_1.argsort()[-k:][::-1]) + list((predict_1 * -1).argsort()[-k:][::-1])))\n",
    "\n",
    "    if predict_2.ndim == 2:\n",
    "        best_values_2 = list(set(np.concatenate((predict_2[:,0].argsort()[-k:][::-1], predict_2[:,1].argsort()[-k:][::-1]))))\n",
    "    else:\n",
    "        best_values_2 = list(set(list(predict_2.argsort()[-k:][::-1]) + list((predict_2 * -1).argsort()[-k:][::-1])))\n",
    "        \n",
    "    for guess in best_values_1:\n",
    "        Labeled_X_train = np.vstack([Labeled_X_train, np.append(Unlabeled_X_train_half_1[guess], Unlabeled_X_train_half_2[guess])])\n",
    "        if model_to_use == 0:\n",
    "            if predict_1.ndim == 2:\n",
    "                Labeled_y_train = np.vstack([Labeled_y_train, to_categorical(np.argmax(predict_1[guess]), num_classes=2)])\n",
    "            else:\n",
    "                Labeled_y_train = np.vstack([Labeled_y_train, to_categorical(np.round(predict_1[guess]), num_classes=2)])\n",
    "        else:\n",
    "            if predict_1.ndim == 2:\n",
    "                Labeled_y_train = np.append(Labeled_y_train, np.argmax(predict_1[guess]))\n",
    "            else:\n",
    "                Labeled_y_train = np.append(Labeled_y_train, np.round(predict_1[guess]))\n",
    "        \n",
    "    for guess in best_values_2:\n",
    "        if guess in best_values_1:\n",
    "            continue\n",
    "        Labeled_X_train = np.vstack([Labeled_X_train, np.append(Unlabeled_X_train_half_1[guess], Unlabeled_X_train_half_2[guess])])\n",
    "        if model_to_use == 0:\n",
    "            if predict_2.ndim == 2:\n",
    "                Labeled_y_train = np.vstack([Labeled_y_train, to_categorical(np.argmax(predict_2[guess]), num_classes=2)])\n",
    "            else:\n",
    "                Labeled_y_train = np.vstack([Labeled_y_train, to_categorical(np.round(predict_2[guess]), num_classes=2)])\n",
    "        else:\n",
    "            if predict_2.ndim == 2:\n",
    "                Labeled_y_train = np.append(Labeled_y_train, np.argmax(predict_2[guess]))\n",
    "            else:\n",
    "                Labeled_y_train = np.append(Labeled_y_train, np.round(predict_2[guess]))\n",
    "\n",
    "    Unlabeled_X_train_half_1 = np.delete(Unlabeled_X_train_half_1, best_values_1, axis=0)\n",
    "    Unlabeled_X_train_half_2 = np.delete(Unlabeled_X_train_half_2, best_values_2, axis=0)\n",
    "    Unlabeled_X_train = np.delete(Unlabeled_X_train, list(set(best_values_1 + best_values_2)), axis=0)\n",
    "    return Unlabeled_X_train_half_1, Unlabeled_X_train_half_2, Unlabeled_X_train, Labeled_X_train, Labeled_y_train, list(set(best_values_1 + best_values_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f031656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model_1, model_2, model_3, model_4, X_test, view_1_ind, view_2_ind, model_to_use):\n",
    "    \n",
    "    predict_1 = model_1.predict(X_test[:,view_1_ind])\n",
    "    predict_2 = model_2.predict(X_test[:,view_2_ind])\n",
    "\n",
    "    if model_to_use == 0:\n",
    "        predict_combined = to_categorical(predict_from_multiple_estimator([model_1, model_2], [X_test[:,view_1_ind], X_test[:,view_2_ind]], model_to_use), num_classes = 2)\n",
    "    else:\n",
    "        predict_combined = predict_from_multiple_estimator([model_1, model_2], [X_test[:,view_1_ind], X_test[:,view_2_ind]], model_to_use)\n",
    "\n",
    "    predict_1 = np.round(predict_1).astype(int)\n",
    "    predict_2 = np.round(predict_2).astype(int)\n",
    "\n",
    "    predict_supervised = np.round(model_3.predict(X_test)).astype(int)\n",
    "    predict_all_supervised = np.round(model_4.predict(X_test)).astype(int)\n",
    "    \n",
    "    return predict_1, predict_2, predict_supervised, predict_all_supervised, predict_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_stats(model_to_use, test_subject, num_data, run, y_test, Labeled_y_train, all_updates=True, predict_updates=None, predict_repeat=None, predict_1=None, predict_2=None, predict_combined=None, predict_supervised=None, predict_all_supervised=None):\n",
    "    \n",
    "    if all_updates:\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['acc']['C1'].append(accuracy_score(y_test, predict_1))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['acc']['C2'].append(accuracy_score(y_test, predict_2))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['acc']['Combined'].append(accuracy_score(y_test, predict_combined))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['acc']['Supervised_partial'].append(accuracy_score(y_test, predict_supervised))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['acc']['Supervised_full'].append(accuracy_score(y_test, predict_all_supervised))\n",
    "\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['roc']['C1'].append(roc_auc_score(y_test, predict_1))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['roc']['C2'].append(roc_auc_score(y_test, predict_2))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['roc']['Combined'].append(roc_auc_score(y_test, predict_combined))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['roc']['Supervised_partial'].append(roc_auc_score(y_test, predict_supervised))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['roc']['Supervised_full'].append(roc_auc_score(y_test, predict_all_supervised))\n",
    "        \n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['f1']['C1'].append(f1_score(y_test, predict_1, average='weighted', zero_division=0))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['f1']['C2'].append(f1_score(y_test, predict_2, average='weighted', zero_division=0))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['f1']['Combined'].append(f1_score(y_test, predict_combined, average='weighted', zero_division=0))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['f1']['Supervised_partial'].append(f1_score(y_test, predict_supervised, average='weighted', zero_division=0))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['f1']['Supervised_full'].append(f1_score(y_test, predict_all_supervised, average='weighted', zero_division=0))\n",
    "    else:\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['acc']['Supervised_updates'].append(accuracy_score(y_test, predict_updates))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['roc']['Supervised_updates'].append(roc_auc_score(y_test, predict_updates))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['f1']['Supervised_updates'].append(f1_score(y_test, predict_updates, average='weighted', zero_division=0))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['acc']['Supervised_repeat'].append(roc_auc_score(y_test, predict_repeat))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['roc']['Supervised_repeat'].append(roc_auc_score(y_test, predict_repeat))\n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['f1']['Supervised_repeat'].append(f1_score(y_test, predict_repeat, average='weighted', zero_division=0))\n",
    "        \n",
    "        all_data[str(model_to_use)][test_subject][str(num_data)][str(run)]['data_points'].append(len(Labeled_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sub = sys.argv[1]\n",
    "# t_sub = 'S2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_dict():\n",
    "    all_data = {\n",
    "        str(model_to_use): {\n",
    "            t_sub: {\n",
    "                str(num_data): {\n",
    "                    str(run): {\n",
    "                        'data_points': [],\n",
    "                        'acc': {\n",
    "                            'C1': [],\n",
    "                            'C2': [],\n",
    "                            'Combined': [],\n",
    "                            'Supervised_partial': [],\n",
    "                            'Supervised_full': [],\n",
    "                            'Supervised_updates': [],\n",
    "                            'Supervised_repeat': []\n",
    "                        }, \n",
    "                        'roc': {\n",
    "                            'C1': [],\n",
    "                            'C2': [],\n",
    "                            'Combined': [],\n",
    "                            'Supervised_partial': [],\n",
    "                            'Supervised_full': [],\n",
    "                            'Supervised_updates': [],\n",
    "                            'Supervised_repeat': []\n",
    "                        },\n",
    "                        'f1': {\n",
    "                            'C1': [],\n",
    "                            'C2': [],\n",
    "                            'Combined': [],\n",
    "                            'Supervised_partial': [],\n",
    "                            'Supervised_full': [],\n",
    "                            'Supervised_updates': [],\n",
    "                            'Supervised_repeat': []\n",
    "                        }\n",
    "                    } for run in range(runs)\n",
    "                } for num_data in testing_range\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = get_stats_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9263ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3a7f4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def run_one_subject(test_subject):\n",
    "    print(\"Working on {0}\".format(test_subject))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = get_data_with_gm_or_im_data(test_subject, MODEL_TYPE)\n",
    "    X_train, X_test, view_1_ind, view_2_ind = filer_and_clean_data(X_train, X_test)\n",
    "    \n",
    "    if DATA == 1:\n",
    "        y_train = np.array([0 if x in [1, 2, 3, 4] else 1 if x in [5, 6, 7, 8] else -1 for x in y_train])\n",
    "        y_test = np.array([0 if x in [1, 2, 3, 4] else 1 if x in [5, 6, 7, 8] else -1 for x in y_test])\n",
    "\n",
    "    if model_to_use == 0:\n",
    "        y_train = to_categorical(y_train, num_classes=2)\n",
    "        y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "    for num_data in testing_range:\n",
    "\n",
    "        for run in range(runs):\n",
    "            \n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "            \n",
    "            num_of_each_label = int((num_data / 100 * len(y_train)) / 2)\n",
    "            elements_to_choose = np.concatenate((np.random.choice(np.where(y_train == 0)[0], num_of_each_label), np.random.choice(np.where(y_train == 1)[0], num_of_each_label)))\n",
    "            elements_for_unlabeled = [x if x not in elements_to_choose else None for x in range(len(y_train))]\n",
    "            elements_for_unlabeled = np.array(list(filter(None, elements_for_unlabeled)))\n",
    "            \n",
    "            Labeled_X_train = X_train[elements_to_choose]\n",
    "            if DATA == 0:\n",
    "                Labeled_y_train = y_train.values[elements_to_choose]\n",
    "            elif DATA == 1:\n",
    "                Labeled_y_train = y_train[elements_to_choose]\n",
    "            \n",
    "            Labeled_X_train, Labeled_y_train = shuffle(Labeled_X_train, Labeled_y_train)\n",
    "            \n",
    "            Labeled_X_train_c = Labeled_X_train.copy()\n",
    "            Labeled_y_train_c = Labeled_y_train.copy()\n",
    "\n",
    "            Unlabeled_X_train = X_train[ elements_for_unlabeled  ]\n",
    "            \n",
    "            if DATA == 0:\n",
    "                Unlabeled_y_train = y_train.values[ elements_for_unlabeled ]\n",
    "            elif DATA == 1:\n",
    "                Unlabeled_y_train = y_train[ elements_for_unlabeled ]\n",
    "\n",
    "            model_1, model_2, model_3, model_4 = get_model()\n",
    "\n",
    "            if model_to_use == 0:\n",
    "                model_3.fit(Labeled_X_train, Labeled_y_train, verbose = 0)\n",
    "                model_4.fit(X_train, y_train, verbose = 0)\n",
    "            else:\n",
    "                model_3.fit(Labeled_X_train, Labeled_y_train)\n",
    "                model_4.fit(X_train, y_train)\n",
    "\n",
    "            predict_updates = model_3.predict(X_test)\n",
    "            update_stats(model_to_use, test_subject, num_data, run, y_test, Labeled_y_train, all_updates=False, predict_updates=predict_updates, predict_repeat=predict_updates)\n",
    "            \n",
    "            elements_for_u_prime = np.concatenate((np.random.choice(np.where(Unlabeled_y_train == 0)[0], int(U_prime_size / 2)), np.random.choice(np.where(Unlabeled_y_train == 1)[0], int(U_prime_size / 2))))\n",
    "            \n",
    "            U_prime = Unlabeled_X_train[elements_for_u_prime]\n",
    "            U_prime_y = Unlabeled_y_train[elements_for_u_prime]\n",
    "            \n",
    "            Unlabeled_X_train = np.delete(Unlabeled_X_train, elements_for_u_prime, axis=0)\n",
    "            Unlabeled_y_train = np.delete(Unlabeled_y_train, elements_for_u_prime, axis=0)\n",
    "            \n",
    "            while True:\n",
    "\n",
    "                X_train_half_1 = Labeled_X_train[:,view_1_ind]\n",
    "                X_train_half_2 = Labeled_X_train[:,view_2_ind]\n",
    "\n",
    "                if model_to_use == 0:\n",
    "                    model_1.fit(X_train_half_1, Labeled_y_train, verbose = 0)\n",
    "                    model_2.fit(X_train_half_2, Labeled_y_train, verbose = 0)\n",
    "                else:\n",
    "                    model_1.fit(X_train_half_1, Labeled_y_train)\n",
    "                    model_2.fit(X_train_half_2, Labeled_y_train)\n",
    "\n",
    "                Unlabeled_X_train_half_1 = U_prime[:,view_1_ind]\n",
    "                Unlabeled_X_train_half_2 = U_prime[:,view_2_ind]\n",
    "                \n",
    "                Unlabeled_X_train_half_1, Unlabeled_X_train_half_2, U_prime, Labeled_X_train, Labeled_y_train, Deleted_Index = update_labels(model_1, model_2, Unlabeled_X_train_half_1, Unlabeled_X_train_half_2, Labeled_X_train, Labeled_y_train, U_prime)\n",
    "                \n",
    "                elements_for_u_prime_new = None\n",
    "                if Unlabeled_X_train.shape[0] > 0:\n",
    "                    count_of_deleted_neg_labels = len(np.where(U_prime_y[Deleted_Index] == 0)[0])\n",
    "                    count_of_deleted_pos_labels = len(np.where(U_prime_y[Deleted_Index] == 1)[0])\n",
    "                    \n",
    "                    try:\n",
    "                        elements_for_u_prime_new = np.concatenate(( np.unique(  np.random.choice(np.where(Unlabeled_y_train == 0)[0], count_of_deleted_neg_labels, replace=False)   ) , np.unique(  np.random.choice(np.where(Unlabeled_y_train == 1)[0], count_of_deleted_pos_labels, replace=False))))\n",
    "                        elements_for_u_prime = np.concatenate((elements_for_u_prime, elements_for_u_prime_new))\n",
    "                    except:\n",
    "                        if len(np.where(Unlabeled_y_train == 0)[0]) == 0 and not len(np.where(Unlabeled_y_train == 1)[0]) == 0:\n",
    "                            try:\n",
    "                                elements_for_u_prime_new = np.unique(  np.random.choice(  [x for x in range(Unlabeled_y_train.shape[0])]  , count_of_deleted_pos_labels + count_of_deleted_neg_labels, replace=False))\n",
    "                            except:\n",
    "                                elements_for_u_prime_new = np.unique(  np.random.choice([x for x in range(Unlabeled_y_train.shape[0])], count_of_deleted_pos_labels + count_of_deleted_neg_labels))\n",
    "                            elements_for_u_prime = np.concatenate((elements_for_u_prime, elements_for_u_prime_new))\n",
    "                        elif len(np.where(Unlabeled_y_train == 1)[0]) == 0 and not len(np.where(Unlabeled_y_train == 0)[0]) == 0:\n",
    "                            try:\n",
    "                                elements_for_u_prime_new = np.unique(  np.random.choice([x for x in range(Unlabeled_y_train.shape[0])], count_of_deleted_pos_labels + count_of_deleted_neg_labels, replace=False))\n",
    "                            except:\n",
    "                                elements_for_u_prime_new = np.unique(  np.random.choice([x for x in range(Unlabeled_y_train.shape[0])], count_of_deleted_pos_labels + count_of_deleted_neg_labels))\n",
    "                            elements_for_u_prime = np.concatenate((elements_for_u_prime, elements_for_u_prime_new))\n",
    "                        else:\n",
    "                            elements_for_u_prime_new = np.concatenate(( np.unique(  np.random.choice(np.where(Unlabeled_y_train == 0)[0], count_of_deleted_neg_labels)   ) , np.unique(  np.random.choice(np.where(Unlabeled_y_train == 1)[0], count_of_deleted_pos_labels))))\n",
    "                            elements_for_u_prime = np.concatenate((elements_for_u_prime, elements_for_u_prime_new))\n",
    "                            \n",
    "\n",
    "                    try:\n",
    "                        U_prime = np.concatenate((Unlabeled_X_train[elements_for_u_prime_new], U_prime))\n",
    "                        U_prime_y = np.concatenate((Unlabeled_y_train[elements_for_u_prime_new], U_prime_y))\n",
    "                    except:\n",
    "                        print(Unlabeled_X_train.shape)\n",
    "                        print(Unlabeled_y_train.shape)\n",
    "                        print(elements_for_u_prime_new)\n",
    "\n",
    "                    Unlabeled_X_train = np.delete(Unlabeled_X_train, elements_for_u_prime_new, axis=0)\n",
    "                    Unlabeled_y_train = np.delete(Unlabeled_y_train, elements_for_u_prime_new, axis=0)\n",
    "                \n",
    "                model = get_model(all_models=False)\n",
    "                model.fit(Labeled_X_train, Labeled_y_train)\n",
    "                predict_updates = model.predict(X_test)\n",
    "                \n",
    "                model = get_model(all_models=False)\n",
    "                model.fit(Labeled_X_train_c, Labeled_y_train_c)\n",
    "                predict_repeat = model.predict(X_test)\n",
    "                update_stats(model_to_use, test_subject, num_data, run, y_test, Labeled_y_train, all_updates=False, predict_updates=predict_updates, predict_repeat=predict_repeat)\n",
    "                \n",
    "                print(len(Unlabeled_X_train))\n",
    "                print(len(U_prime))\n",
    "                print()\n",
    "                \n",
    "                \n",
    "                if Unlabeled_y_train.shape[0] == 0 and len(U_prime) == 0: break\n",
    "            print(\"Done with\", num_data)\n",
    "            print()\n",
    "            predict_1, predict_2, predict_supervised, predict_all_supervised, predict_combined = get_predictions(model_1, model_2, model_3, model_4, X_test, view_1_ind, view_2_ind, model_to_use)\n",
    "            update_stats(model_to_use, test_subject, num_data, run, y_test, Labeled_y_train, predict_1=predict_1, predict_2=predict_2, predict_combined=predict_combined, predict_supervised=predict_supervised, predict_all_supervised=predict_all_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca20651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = {}\n",
    "for subject in subjects:\n",
    "    path = 'Data/WESAD/GeneratedData/features_wesad_{0}_{1}.p'.format(subject, window_size_features)\n",
    "    with open(path, 'rb') as file:\n",
    "        all_features[subject] = pd.DataFrame(pickle.load(file, encoding='latin1')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a065bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_one_subject(t_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TestingResults/{0}/runs_{1}_k_{2}_subject_{3}.json'.format('WESAD', runs, k, t_sub), 'w') as fp:\n",
    "    json.dump(all_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082150bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628df973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39207787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e09b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a2e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a76bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb3693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d4381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0c070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c8dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908382c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running_all_for_control = {\n",
    "#     num_data: {\n",
    "#         \"F1\": [],\n",
    "#         \"ACC\": [],\n",
    "#         \"ROC\": [],\n",
    "#     }for num_data in testing_range\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb24cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num_data in testing_range:\n",
    "    \n",
    "#     for run in range(runs):\n",
    "        \n",
    "#         X_train, X_test, y_train, y_test = get_data_with_gm_or_im_data(np.random.choice(all_subjects), MODEL_TYPE)\n",
    "#         X_train, X_test, view_1_ind, view_2_ind = filer_and_clean_data(X_train, X_test)\n",
    "\n",
    "#         if DATA == 1:\n",
    "#             y_train = np.array([0 if x in [1, 2, 3, 4] else 1 if x in [5, 6, 7, 8] else -1 for x in y_train])\n",
    "#             y_test = np.array([0 if x in [1, 2, 3, 4] else 1 if x in [5, 6, 7, 8] else -1 for x in y_test])\n",
    "\n",
    "\n",
    "#         X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "#         num_of_each_label = int((num_data / 100 * len(y_train)) / 2)\n",
    "#         elements_to_choose = np.concatenate((np.random.choice(np.where(y_train == 0)[0], num_of_each_label), np.random.choice(np.where(y_train == 1)[0], num_of_each_label)))\n",
    "#         elements_for_unlabeled = [x if x not in elements_to_choose else None for x in range(len(y_train))]\n",
    "#         elements_for_unlabeled = np.array(list(filter(None, elements_for_unlabeled)))\n",
    "\n",
    "#         Labeled_X_train = X_train[elements_to_choose]\n",
    "#         if DATA == 0:\n",
    "#             Labeled_y_train = y_train.values[elements_to_choose]\n",
    "#         elif DATA == 1:\n",
    "#             Labeled_y_train = y_train[elements_to_choose]\n",
    "\n",
    "#         Labeled_X_train, Labeled_y_train = shuffle(Labeled_X_train, Labeled_y_train)\n",
    "\n",
    "\n",
    "#         clf = RandomForestClassifier(n_estimators=100)\n",
    "#         clf.fit(Labeled_X_train, Labeled_y_train)\n",
    "#         predict = clf.predict(X_test)\n",
    "#         acc = accuracy_score(y_test, predict)\n",
    "#         roc = roc_auc_score(y_test, predict)\n",
    "#         f1 = f1_score(y_test, predict, average='weighted', zero_division=0)\n",
    "\n",
    "#         running_all_for_control[num_data][\"F1\"].append(f1)\n",
    "#         running_all_for_control[num_data][\"ACC\"].append(acc)        \n",
    "#         running_all_for_control[num_data][\"ROC\"].append(roc)    \n",
    "#     print(f\"{num_data} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239766cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('TestingResults/running_all_for_control.json', 'w') as fp:\n",
    "#     json.dump(running_all_for_control, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c959009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce54cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c981c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd4adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b616c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cpu",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
